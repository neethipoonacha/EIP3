{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradcam.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neethipoonacha/EIP3/blob/master/Gradcam_backup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K70hAckqg0EA",
        "colab_type": "code",
        "outputId": "f38179ce-4ab6-490f-b42a-b146c9886a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "\n",
        "\n",
        "!pip install Pillow\n",
        "import scipy"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzPHfdbENy4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChhCXSahODjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lists the content of your google drive\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgOs7XseOicE",
        "colab_type": "code",
        "outputId": "3e32b145-799d-41ec-eefd-4f239ec7fb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#x=File.open('drive/My Drive/test/weight-01-0.33.hdf5')\n",
        "\n",
        "with open('drive/My Drive/test/weight-01-0.33.hdf5', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat drive/My\\ Drive/test/weight-01-0.33.hdf5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVIx_KIigxPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Concatenate\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "#import numpy as np\n",
        "#from scipy.misc import imread, imsave, imresize\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNHw6luQg3gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
        "# backend\n",
        "import tensorflow as tf\n",
        "from keras import backend as k\n",
        "\n",
        "# Don't pre-allocate memory; allocate as-needed\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "\n",
        "# Create a session with the above options specified.\n",
        "k.tensorflow_backend.set_session(tf.Session(config=config))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO_yGxcg5D8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "num_classes = 10\n",
        "epochs = 50\n",
        "l = 40\n",
        "num_filter = 12\n",
        "compression = 0.5\n",
        "dropout_rate = 0.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB7o3zu1g6eT",
        "colab_type": "code",
        "outputId": "f924a65d-7257-4163-b4e7-d718e18ff63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print (x_train.shape)\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaDNCbooRaY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_imgs(X):\n",
        "    pyplot.figure(1)\n",
        "    k = 0\n",
        "    for i in range(0,4):\n",
        "        for j in range(0,4):\n",
        "            pyplot.subplot2grid((4,4),(i,j))\n",
        "            pyplot.imshow(toimage(X[k]))\n",
        "            k = k+1\n",
        "    # show the plot\n",
        "    pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLNjnrIlRkx_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "show_imgs(x_test[:50])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZInQ3yE6SAHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( rotation_range=90, \n",
        "                 width_shift_range=0.1, height_shift_range=0.1, \n",
        "                 horizontal_flip=True) \n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_75hrnVFSE_V",
        "colab_type": "code",
        "outputId": "d828abae-c6f0-438a-cd9b-3e087476fa1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "# Configure batch size and retrieve one batch of images\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    # Show 9 images\n",
        "    for i in range(0, 9):\n",
        "        pyplot.subplot(330 + 1 + i)\n",
        "        pyplot.imshow(toimage(X_batch[i].reshape(x_train.shape[1], x_train.shape[2], 3)))\n",
        "    # show the plot\n",
        "    pyplot.show()\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAFNCAYAAACKdYHuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQUGh5vH/A39wRcW9GCCbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f5920458400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sge5Kg7vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dense Block\n",
        "def add_denseblock(input, num_filter = 64, dropout_rate=0.0, weight_decay=1e-4):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l):\n",
        "        BatchNorm = BatchNormalization()(temp)\n",
        "        relu = Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        if dropout_rate>0:\n",
        "          Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
        "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        \n",
        "        temp = concat\n",
        "        \n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOP6IPsGhBwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_transition(input, num_filter = 32, dropout_rate = 0.1):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    if dropout_rate>0:\n",
        "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
        "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    \n",
        "    return avg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RaKFpubhDIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = BatchNormalization()(input)\n",
        "    relu = Activation('relu')(BatchNorm)\n",
        "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = Flatten()(AvgPooling)\n",
        "    output = Dense(num_classes, activation='softmax')(flat)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anPCpQWhhGb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_filter = 32\n",
        "dropout_rate = 0.2\n",
        "l = 15\n",
        "input = Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = add_denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = add_transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = add_denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = add_transition(Second_Block, num_filter, dropout_rate)\n",
        "dropout_rate = 0.1\n",
        "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = add_transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "#Last_Block = add_denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "\n",
        "output = output_layer(Third_Transition)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFh7pdxhNtT",
        "colab_type": "code",
        "outputId": "b19c7892-4672-430b-fb60-332fcb61372b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 9299
        }
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   4608        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 16)   0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 32, 32, 48)   0           conv2d_1[0][0]                   \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   6912        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 16)   0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 64)   0           concatenate_1[0][0]              \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   9216        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 16)   0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 32, 32, 80)   0           concatenate_2[0][0]              \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 80)   320         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   11520       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 32, 32, 16)   0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 96)   0           concatenate_3[0][0]              \n",
            "                                                                 dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 96)   384         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 96)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   13824       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 32, 32, 16)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 32, 32, 112)  0           concatenate_4[0][0]              \n",
            "                                                                 dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 112)  448         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 112)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   16128       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 32, 32, 16)   0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 32, 32, 128)  0           concatenate_5[0][0]              \n",
            "                                                                 dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 16)   18432       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 32, 32, 16)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 32, 32, 144)  0           concatenate_6[0][0]              \n",
            "                                                                 dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 144)  576         concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 144)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   20736       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32, 32, 16)   0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 32, 32, 160)  0           concatenate_7[0][0]              \n",
            "                                                                 dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 160)  640         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 160)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   23040       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 32, 32, 16)   0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 32, 32, 176)  0           concatenate_8[0][0]              \n",
            "                                                                 dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 176)  704         concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 176)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 16)   25344       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 32, 32, 16)   0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 32, 32, 192)  0           concatenate_9[0][0]              \n",
            "                                                                 dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 192)  768         concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 192)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 16)   27648       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 32, 32, 16)   0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 32, 32, 208)  0           concatenate_10[0][0]             \n",
            "                                                                 dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 208)  832         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 208)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 16)   29952       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 32, 32, 16)   0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 32, 32, 224)  0           concatenate_11[0][0]             \n",
            "                                                                 dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 224)  896         concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 224)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 16)   32256       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 32, 32, 16)   0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 32, 32, 240)  0           concatenate_12[0][0]             \n",
            "                                                                 dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 240)  960         concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 240)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   34560       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 32, 32, 16)   0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 32, 32, 256)  0           concatenate_13[0][0]             \n",
            "                                                                 dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 256)  1024        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   36864       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 32, 32, 16)   0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 32, 32, 272)  0           concatenate_14[0][0]             \n",
            "                                                                 dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 272)  1088        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 272)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 16)   4352        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 32, 32, 16)   0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 16)   0           dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 16)   64          average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 16)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 16)   2304        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 16, 16, 16)   0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 16, 16, 32)   0           average_pooling2d_1[0][0]        \n",
            "                                                                 dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 32)   128         concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 32)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 16)   4608        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 16, 16, 16)   0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 16, 16, 48)   0           concatenate_16[0][0]             \n",
            "                                                                 dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 48)   192         concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 48)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 16)   6912        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 16, 16, 16)   0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 16, 16, 64)   0           concatenate_17[0][0]             \n",
            "                                                                 dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 16)   9216        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 16, 16, 16)   0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 16, 16, 80)   0           concatenate_18[0][0]             \n",
            "                                                                 dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 80)   320         concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 80)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 16)   11520       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 16, 16, 16)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 16, 16, 96)   0           concatenate_19[0][0]             \n",
            "                                                                 dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 96)   384         concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 96)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 16)   13824       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 16, 16, 16)   0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 16, 16, 112)  0           concatenate_20[0][0]             \n",
            "                                                                 dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 112)  448         concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 112)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 16)   16128       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 16, 16, 16)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 16, 16, 128)  0           concatenate_21[0][0]             \n",
            "                                                                 dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 16)   18432       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 16, 16, 16)   0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 16, 16, 144)  0           concatenate_22[0][0]             \n",
            "                                                                 dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 144)  576         concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 144)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 16)   20736       activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 16, 16, 16)   0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 16, 16, 160)  0           concatenate_23[0][0]             \n",
            "                                                                 dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 160)  640         concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 160)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 16)   23040       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 16, 16, 16)   0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 16, 16, 176)  0           concatenate_24[0][0]             \n",
            "                                                                 dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 176)  704         concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 176)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 16)   25344       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 16, 16, 16)   0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 16, 16, 192)  0           concatenate_25[0][0]             \n",
            "                                                                 dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 192)  768         concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 192)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 16)   27648       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 16, 16, 16)   0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 16, 16, 208)  0           concatenate_26[0][0]             \n",
            "                                                                 dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 208)  832         concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 208)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 16)   29952       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_29 (Dropout)            (None, 16, 16, 16)   0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 16, 16, 224)  0           concatenate_27[0][0]             \n",
            "                                                                 dropout_29[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 224)  896         concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 224)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 16)   32256       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_30 (Dropout)            (None, 16, 16, 16)   0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 16, 16, 240)  0           concatenate_28[0][0]             \n",
            "                                                                 dropout_30[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 240)  960         concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 240)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 16)   34560       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_31 (Dropout)            (None, 16, 16, 16)   0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 16, 16, 256)  0           concatenate_29[0][0]             \n",
            "                                                                 dropout_31[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 256)  1024        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 256)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 16)   4096        activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_32 (Dropout)            (None, 16, 16, 16)   0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 8, 8, 16)     0           dropout_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 16)     64          average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 16)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 16)     2304        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_33 (Dropout)            (None, 8, 8, 16)     0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 8, 8, 32)     0           average_pooling2d_2[0][0]        \n",
            "                                                                 dropout_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 32)     128         concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 32)     0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 16)     4608        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_34 (Dropout)            (None, 8, 8, 16)     0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 8, 8, 48)     0           concatenate_31[0][0]             \n",
            "                                                                 dropout_34[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 48)     192         concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 48)     0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 16)     6912        activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_35 (Dropout)            (None, 8, 8, 16)     0           conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 8, 8, 64)     0           concatenate_32[0][0]             \n",
            "                                                                 dropout_35[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 64)     256         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 64)     0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 16)     9216        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_36 (Dropout)            (None, 8, 8, 16)     0           conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 8, 8, 80)     0           concatenate_33[0][0]             \n",
            "                                                                 dropout_36[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 80)     320         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 80)     0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 16)     11520       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 8, 8, 16)     0           conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 8, 8, 96)     0           concatenate_34[0][0]             \n",
            "                                                                 dropout_37[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 96)     384         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 96)     0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 16)     13824       activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 16)     0           conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 8, 8, 112)    0           concatenate_35[0][0]             \n",
            "                                                                 dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 112)    448         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 112)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 16)     16128       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 8, 8, 16)     0           conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 8, 8, 128)    0           concatenate_36[0][0]             \n",
            "                                                                 dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 128)    512         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 16)     18432       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 16)     0           conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 8, 8, 144)    0           concatenate_37[0][0]             \n",
            "                                                                 dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 144)    576         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 144)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 16)     20736       activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 16)     0           conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 8, 8, 160)    0           concatenate_38[0][0]             \n",
            "                                                                 dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 160)    640         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 8, 8, 16)     23040       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 16)     0           conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 8, 8, 176)    0           concatenate_39[0][0]             \n",
            "                                                                 dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 176)    704         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 176)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 8, 8, 16)     25344       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 8, 8, 16)     0           conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 8, 8, 192)    0           concatenate_40[0][0]             \n",
            "                                                                 dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 192)    768         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 192)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 8, 8, 16)     27648       activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 8, 8, 16)     0           conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 8, 8, 208)    0           concatenate_41[0][0]             \n",
            "                                                                 dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 208)    832         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 208)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 8, 8, 16)     29952       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 16)     0           conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 8, 8, 224)    0           concatenate_42[0][0]             \n",
            "                                                                 dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 224)    896         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 224)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 16)     32256       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 8, 8, 16)     0           conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 8, 8, 240)    0           concatenate_43[0][0]             \n",
            "                                                                 dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 240)    960         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 240)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 16)     34560       activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 8, 8, 16)     0           conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 8, 8, 256)    0           concatenate_44[0][0]             \n",
            "                                                                 dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 256)    1024        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 256)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 16)     4096        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 8, 8, 16)     0           conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 4, 4, 16)     0           dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 16)     64          average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 4, 4, 16)     0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 2, 2, 16)     0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 64)           0           average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 10)           650         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 905,258\n",
            "Trainable params: 891,658\n",
            "Non-trainable params: 13,600\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XOsW3ahSkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.1 ,decay=1e-4,momentum=0.9),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pjKw_E9XH7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.1\n",
        "    if epoch > 32:\n",
        "        lrate = 0.15\n",
        "    elif epoch > 48:\n",
        "        lrate = 0.2        \n",
        "    return lrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QudA66i6gaCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( rotation_range=90, \n",
        "                 width_shift_range=0.1, height_shift_range=0.1, \n",
        "                 horizontal_flip=True) \n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crhGk7kEhXAz",
        "colab_type": "code",
        "outputId": "0c6db5c0-223c-4ff2-baa5-1b05fd038776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1091
        }
      },
      "source": [
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                       #       patience=5, min_lr=0.001)\n",
        "\n",
        "\n",
        "#training\n",
        "batch_size = 128\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=30,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "\n",
        "#model.save_weights('drive/My\\ Drive/test/weight-01-0.33.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
            "Epoch 1/30\n",
            "390/390 [==============================] - 321s 824ms/step - loss: 1.8202 - acc: 0.3353 - val_loss: 2.4529 - val_acc: 0.2688\n",
            "Epoch 2/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 1.6394 - acc: 0.4027 - val_loss: 1.9500 - val_acc: 0.3669\n",
            "Epoch 3/30\n",
            "390/390 [==============================] - 300s 770ms/step - loss: 1.5003 - acc: 0.4551 - val_loss: 1.8553 - val_acc: 0.4286\n",
            "Epoch 4/30\n",
            "390/390 [==============================] - 300s 770ms/step - loss: 1.3820 - acc: 0.4963 - val_loss: 2.4107 - val_acc: 0.3491\n",
            "Epoch 5/30\n",
            "390/390 [==============================] - 300s 770ms/step - loss: 1.2969 - acc: 0.5336 - val_loss: 2.1739 - val_acc: 0.4000\n",
            "Epoch 6/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 1.2280 - acc: 0.5585 - val_loss: 2.0932 - val_acc: 0.4455\n",
            "Epoch 7/30\n",
            "390/390 [==============================] - 300s 770ms/step - loss: 1.1696 - acc: 0.5817 - val_loss: 1.2144 - val_acc: 0.5877\n",
            "Epoch 8/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 1.1156 - acc: 0.6027 - val_loss: 1.9618 - val_acc: 0.4227\n",
            "Epoch 9/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 1.0663 - acc: 0.6209 - val_loss: 1.8547 - val_acc: 0.5165\n",
            "Epoch 10/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 1.0228 - acc: 0.6388 - val_loss: 1.6683 - val_acc: 0.5400\n",
            "Epoch 11/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 0.9930 - acc: 0.6482 - val_loss: 1.6251 - val_acc: 0.5590\n",
            "Epoch 12/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 0.9656 - acc: 0.6597 - val_loss: 1.2920 - val_acc: 0.5745\n",
            "Epoch 13/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 0.9405 - acc: 0.6674 - val_loss: 1.5868 - val_acc: 0.5792\n",
            "Epoch 14/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.9144 - acc: 0.6801 - val_loss: 1.5458 - val_acc: 0.5722\n",
            "Epoch 15/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.8887 - acc: 0.6872 - val_loss: 1.0768 - val_acc: 0.6573\n",
            "Epoch 16/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.8767 - acc: 0.6926 - val_loss: 1.1014 - val_acc: 0.6723\n",
            "Epoch 17/30\n",
            "390/390 [==============================] - 300s 770ms/step - loss: 0.8559 - acc: 0.7014 - val_loss: 1.2756 - val_acc: 0.6298\n",
            "Epoch 18/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.8383 - acc: 0.7052 - val_loss: 1.2917 - val_acc: 0.6322\n",
            "Epoch 19/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.8219 - acc: 0.7132 - val_loss: 1.0875 - val_acc: 0.6687\n",
            "Epoch 20/30\n",
            "390/390 [==============================] - 301s 772ms/step - loss: 0.8054 - acc: 0.7182 - val_loss: 1.2747 - val_acc: 0.6294\n",
            "Epoch 21/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.7908 - acc: 0.7237 - val_loss: 1.0779 - val_acc: 0.6583\n",
            "Epoch 22/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.7741 - acc: 0.7314 - val_loss: 1.0635 - val_acc: 0.6725\n",
            "Epoch 23/30\n",
            "390/390 [==============================] - 301s 771ms/step - loss: 0.7628 - acc: 0.7357 - val_loss: 1.1090 - val_acc: 0.6762\n",
            "Epoch 24/30\n",
            "390/390 [==============================] - 301s 772ms/step - loss: 0.7533 - acc: 0.7367 - val_loss: 1.0418 - val_acc: 0.6832\n",
            "Epoch 25/30\n",
            "390/390 [==============================] - 301s 772ms/step - loss: 0.7381 - acc: 0.7429 - val_loss: 0.9752 - val_acc: 0.7081\n",
            "Epoch 26/30\n",
            "390/390 [==============================] - 300s 769ms/step - loss: 0.7321 - acc: 0.7459 - val_loss: 1.1517 - val_acc: 0.6586\n",
            "Epoch 27/30\n",
            "390/390 [==============================] - 299s 768ms/step - loss: 0.7186 - acc: 0.7522 - val_loss: 1.0230 - val_acc: 0.7045\n",
            "Epoch 28/30\n",
            "390/390 [==============================] - 298s 764ms/step - loss: 0.7033 - acc: 0.7554 - val_loss: 0.9617 - val_acc: 0.7165\n",
            "Epoch 29/30\n",
            "390/390 [==============================] - 298s 764ms/step - loss: 0.6991 - acc: 0.7557 - val_loss: 0.8994 - val_acc: 0.7201\n",
            "Epoch 30/30\n",
            "390/390 [==============================] - 298s 764ms/step - loss: 0.6854 - acc: 0.7626 - val_loss: 0.9388 - val_acc: 0.7203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5908812668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UE3lF6EH1r_L",
        "colab_type": "code",
        "outputId": "05a4be81-db08-428d-edf9-91c21751199d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_one_save.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ai-yZ2ED5AK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model_one_save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rocaVh79cUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imgAug = ImageDataGenerator(rotation_range=60,width_shift_range=0.1, zoom_range=0.1,horizontal_flip=True, height_shift_range=0.1)\n",
        "#imgAug.fit(x_train)\n",
        "\n",
        "#data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og56VCRh5j8V",
        "colab_type": "code",
        "outputId": "f550830d-0cad-42b1-ee5e-a04ecd81494d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "\n",
        "#reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                          #    patience=5, min_lr=0.001)\n",
        "\n",
        "model.load_weights(\"DNST_model_one_save.h5\")\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.15 ,decay=1e-6,momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch= 2*x_train.shape[0] // batch_size,epochs=20,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "\n",
        "model.save_weights(\"DNST_model_two_save.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "781/781 [==============================] - 588s 753ms/step - loss: 0.5403 - acc: 0.8141 - val_loss: 0.9019 - val_acc: 0.7562\n",
            "Epoch 2/20\n",
            "781/781 [==============================] - 576s 738ms/step - loss: 0.4472 - acc: 0.8458 - val_loss: 0.8675 - val_acc: 0.7347\n",
            "Epoch 3/20\n",
            "781/781 [==============================] - 576s 738ms/step - loss: 0.3924 - acc: 0.8644 - val_loss: 0.6566 - val_acc: 0.8014\n",
            "Epoch 4/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.3573 - acc: 0.8777 - val_loss: 0.4442 - val_acc: 0.8588\n",
            "Epoch 5/20\n",
            "781/781 [==============================] - 580s 743ms/step - loss: 0.3299 - acc: 0.8851 - val_loss: 0.6905 - val_acc: 0.8004\n",
            "Epoch 6/20\n",
            "781/781 [==============================] - 580s 743ms/step - loss: 0.3096 - acc: 0.8943 - val_loss: 0.5004 - val_acc: 0.8469\n",
            "Epoch 7/20\n",
            "781/781 [==============================] - 579s 742ms/step - loss: 0.2838 - acc: 0.9020 - val_loss: 0.4306 - val_acc: 0.8645\n",
            "Epoch 8/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.2711 - acc: 0.9061 - val_loss: 0.4739 - val_acc: 0.8601\n",
            "Epoch 9/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.2542 - acc: 0.9121 - val_loss: 0.4028 - val_acc: 0.8772\n",
            "Epoch 10/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.2416 - acc: 0.9163 - val_loss: 0.4274 - val_acc: 0.8693\n",
            "Epoch 11/20\n",
            "781/781 [==============================] - 578s 740ms/step - loss: 0.2337 - acc: 0.9182 - val_loss: 0.5809 - val_acc: 0.8409\n",
            "Epoch 12/20\n",
            "781/781 [==============================] - 578s 740ms/step - loss: 0.2179 - acc: 0.9247 - val_loss: 0.5234 - val_acc: 0.8664\n",
            "Epoch 13/20\n",
            "781/781 [==============================] - 578s 740ms/step - loss: 0.2105 - acc: 0.9266 - val_loss: 0.6342 - val_acc: 0.8271\n",
            "Epoch 14/20\n",
            "781/781 [==============================] - 578s 740ms/step - loss: 0.2002 - acc: 0.9301 - val_loss: 0.4778 - val_acc: 0.8750\n",
            "Epoch 15/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.1948 - acc: 0.9321 - val_loss: 0.4661 - val_acc: 0.8698\n",
            "Epoch 16/20\n",
            "781/781 [==============================] - 578s 740ms/step - loss: 0.1847 - acc: 0.9349 - val_loss: 0.5397 - val_acc: 0.8603\n",
            "Epoch 17/20\n",
            "781/781 [==============================] - 578s 739ms/step - loss: 0.1815 - acc: 0.9356 - val_loss: 0.3936 - val_acc: 0.8889\n",
            "Epoch 18/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.1721 - acc: 0.9396 - val_loss: 0.4146 - val_acc: 0.8809\n",
            "Epoch 19/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.1672 - acc: 0.9410 - val_loss: 0.4262 - val_acc: 0.8898\n",
            "Epoch 20/20\n",
            "781/781 [==============================] - 577s 739ms/step - loss: 0.1601 - acc: 0.9439 - val_loss: 0.4401 - val_acc: 0.8854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1fFRMGt9pFY",
        "colab_type": "code",
        "outputId": "ca94a8ca-e392-48cd-f494-d46e1f0e1689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 26s 3ms/step\n",
            "Test loss: 0.44008580334186553\n",
            "Test accuracy: 0.8854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMCYGr8D9wzs",
        "colab_type": "code",
        "outputId": "550bf42f-9908-466a-c5ba-1f8fae7e19d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_two_save.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25QrJbZ496Mx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model_two_save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru6RqmVt96Jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data augmentation\n",
        "datagen = ImageDataGenerator(    \n",
        "    horizontal_flip=True\n",
        "    )\n",
        "datagen.fit(x_train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gMxTSsX-IKK",
        "colab_type": "code",
        "outputId": "9c9ac9b4-13f4-4c64-f70e-1f94a19976f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "\n",
        "model.load_weights(\"DNST_model_two_save.h5\")\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.01 ,decay=1e-10,momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
        "                    steps_per_epoch= x_train.shape[0] // batch_size,epochs=10,\\\n",
        "                    verbose=1,validation_data=(x_test,y_test))\n",
        "\n",
        "\n",
        "model.save_weights(\"DNST_model_three_save.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "781/781 [==============================] - 350s 448ms/step - loss: 0.1176 - acc: 0.9587 - val_loss: 0.3127 - val_acc: 0.9141\n",
            "Epoch 2/10\n",
            "781/781 [==============================] - 335s 429ms/step - loss: 0.1086 - acc: 0.9612 - val_loss: 0.3145 - val_acc: 0.9190\n",
            "Epoch 3/10\n",
            "781/781 [==============================] - 336s 430ms/step - loss: 0.0967 - acc: 0.9655 - val_loss: 0.3121 - val_acc: 0.9176\n",
            "Epoch 4/10\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.0939 - acc: 0.9664 - val_loss: 0.3244 - val_acc: 0.9190\n",
            "Epoch 5/10\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.0914 - acc: 0.9677 - val_loss: 0.3342 - val_acc: 0.9189\n",
            "Epoch 6/10\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.0910 - acc: 0.9672 - val_loss: 0.3264 - val_acc: 0.9190\n",
            "Epoch 7/10\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.0845 - acc: 0.9701 - val_loss: 0.3266 - val_acc: 0.9198\n",
            "Epoch 8/10\n",
            "781/781 [==============================] - 338s 432ms/step - loss: 0.0850 - acc: 0.9695 - val_loss: 0.3321 - val_acc: 0.9184\n",
            "Epoch 9/10\n",
            "781/781 [==============================] - 337s 432ms/step - loss: 0.0821 - acc: 0.9709 - val_loss: 0.3370 - val_acc: 0.9188\n",
            "Epoch 10/10\n",
            "781/781 [==============================] - 337s 431ms/step - loss: 0.0820 - acc: 0.9702 - val_loss: 0.3500 - val_acc: 0.9185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sY5-4BjsWS1S",
        "colab_type": "code",
        "outputId": "6e279175-6319-4c64-c670-313a178a4914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 26s 3ms/step\n",
            "Test loss: 0.3500478660710156\n",
            "Test accuracy: 0.9185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoMarAXAWXgH",
        "colab_type": "code",
        "outputId": "e7c90473-92b1-41e1-a25a-47cb0dd067e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_three_save.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t894MoIQWegg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model_three_save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1mdmPjMWq1U",
        "colab_type": "code",
        "outputId": "56cd6c48-8a10-4be7-8f6d-a5248bef31bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2190
        }
      },
      "source": [
        "#datagen = ImageDataGenerator(\n",
        "  #  horizontal_flip=True\n",
        "  #  )\n",
        "#datagen.fit(x_train)\n",
        "\n",
        "\n",
        "\n",
        "model.load_weights(\"DNST_model_three_save.h5\")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=5, min_lr=0.001)\n",
        "batch_size=64\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy',\n",
        "            #  optimizer=SGD(lr=0.001 ,decay=1e-4,momentum=0.9),\n",
        "            #  metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "                    batch_size=64,\n",
        "                    epochs=250,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test),callbacks=[reduce_lr])\n",
        "\n",
        "model.save_weights(\"DNST_model_four_save.h5\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/250\n",
            "50000/50000 [==============================] - 346s 7ms/step - loss: 0.0758 - acc: 0.9726 - val_loss: 0.3350 - val_acc: 0.9206\n",
            "Epoch 2/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0735 - acc: 0.9739 - val_loss: 0.3293 - val_acc: 0.9212\n",
            "Epoch 3/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0722 - acc: 0.9738 - val_loss: 0.3332 - val_acc: 0.9208\n",
            "Epoch 4/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0719 - acc: 0.9747 - val_loss: 0.3340 - val_acc: 0.9206\n",
            "Epoch 5/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0729 - acc: 0.9742 - val_loss: 0.3331 - val_acc: 0.9212\n",
            "Epoch 6/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0725 - acc: 0.9740 - val_loss: 0.3334 - val_acc: 0.9204\n",
            "Epoch 7/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0740 - acc: 0.9730 - val_loss: 0.3331 - val_acc: 0.9202\n",
            "Epoch 8/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0695 - acc: 0.9753 - val_loss: 0.3339 - val_acc: 0.9207\n",
            "Epoch 9/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0699 - acc: 0.9746 - val_loss: 0.3313 - val_acc: 0.9207\n",
            "Epoch 10/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0696 - acc: 0.9753 - val_loss: 0.3352 - val_acc: 0.9204\n",
            "Epoch 11/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0709 - acc: 0.9746 - val_loss: 0.3335 - val_acc: 0.9211\n",
            "Epoch 12/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0684 - acc: 0.9755 - val_loss: 0.3353 - val_acc: 0.9199\n",
            "Epoch 13/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0709 - acc: 0.9744 - val_loss: 0.3354 - val_acc: 0.9205\n",
            "Epoch 14/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0663 - acc: 0.9761 - val_loss: 0.3354 - val_acc: 0.9202\n",
            "Epoch 15/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0686 - acc: 0.9759 - val_loss: 0.3347 - val_acc: 0.9213\n",
            "Epoch 16/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0680 - acc: 0.9756 - val_loss: 0.3358 - val_acc: 0.9207\n",
            "Epoch 17/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0687 - acc: 0.9759 - val_loss: 0.3341 - val_acc: 0.9206\n",
            "Epoch 18/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0692 - acc: 0.9750 - val_loss: 0.3359 - val_acc: 0.9205\n",
            "Epoch 19/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0683 - acc: 0.9758 - val_loss: 0.3367 - val_acc: 0.9201\n",
            "Epoch 20/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0679 - acc: 0.9759 - val_loss: 0.3353 - val_acc: 0.9204\n",
            "Epoch 21/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0680 - acc: 0.9761 - val_loss: 0.3346 - val_acc: 0.9207\n",
            "Epoch 22/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0677 - acc: 0.9753 - val_loss: 0.3366 - val_acc: 0.9203\n",
            "Epoch 23/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0673 - acc: 0.9758 - val_loss: 0.3373 - val_acc: 0.9205\n",
            "Epoch 24/250\n",
            "50000/50000 [==============================] - 336s 7ms/step - loss: 0.0692 - acc: 0.9754 - val_loss: 0.3369 - val_acc: 0.9212\n",
            "Epoch 25/250\n",
            " 1728/50000 [>.............................] - ETA: 5:02 - loss: 0.0850 - acc: 0.9688"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-14b92e86fa0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     validation_data=(x_test, y_test),callbacks=[reduce_lr])\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNST_model_four_save.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ia_CNLLfJxF6",
        "colab_type": "code",
        "outputId": "e55b4389-10e6-4dd9-d6d4-d7beea3f398d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 26s 3ms/step\n",
            "Test loss: 0.3363751113705337\n",
            "Test accuracy: 0.9209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UdMulfkKEWL",
        "colab_type": "code",
        "outputId": "815535b5-70c8-41b2-9985-98901b9d4cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model_four_save.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmD-WCutKLRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('DNST_model_four_save.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSPNXZr8pu-w",
        "colab_type": "code",
        "outputId": "6f5a1f03-c1bd-48b0-8492-8a9cf80c743c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 26s 3ms/step\n",
            "Test loss: 0.3363751113705337\n",
            "Test accuracy: 0.9209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLCEJggpkKtg",
        "colab_type": "text"
      },
      "source": [
        "Weights are loaded and saved from disk ,Due to security issues was not able to  connect to google drive via office network\n",
        "\n",
        "DNST_model_one_save.h5   https://drive.google.com/file/d/1ZqTvWcSFZV9xDFoSo2vZHX1Z0spPbSey/view?usp=sharing\n",
        "\n",
        "DNST_model_two_save.h5 https://drive.google.com/file/d/1p0wLKjl-h6pU4-mQmwDPHGGGMhTtQOjJ/view?usp=sharing\n",
        "\n",
        "DNST_model_three_save.h5 https://drive.google.com/file/d/1DIsnAVvePizUNZH-sQjPSQpifDjBT1DP/view?usp=sharing\n",
        "\n",
        "DNST_model_four_save.h5 https://drive.google.com/file/d/1wIE1QARyX8A8HW0AvZNHtAkjwvHKOtoG/view?usp=sharing\n"
      ]
    }
  ]
}