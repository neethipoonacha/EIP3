{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment14_v4_augmented.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neethipoonacha/EIP3/blob/master/Assignment14_v4_augmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwa59cXgdshz",
        "colab_type": "code",
        "outputId": "e905c740-7b27-4f44-cacf-649376fc8dfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i00Og0AITpUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import argparse\n",
        "from glob import glob\n",
        "from pprint import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "\n",
        "import sys\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwHUm1Xudu09",
        "colab_type": "code",
        "outputId": "2da910d0-9a3b-48d5-b622-d41dff35c9af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.test.gpu_device_name() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQR_JVd2du4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/session14/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxbibxQUJ0pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS=tf.app.flags.FLAGS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvpyArUdMl1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic model parameters.\n",
        "tf.app.flags.DEFINE_integer('batch_size', 128,\n",
        "                            \"\"\"Number of images to process in a batch.\"\"\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-GLGbhaMl4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOWER_NAME = 'tower'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd6xsZpVMly7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu-FYEydtpre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JvWgtdUYrv0",
        "colab_type": "text"
      },
      "source": [
        "### Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_5gtx98YtX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'\n",
        "\n",
        "\n",
        "def maybe_download_and_extract(data_dir='data'):\n",
        "    \"\"\"Download and extract the tarball from Alex's website.\"\"\"\n",
        "    dest_directory = data_dir\n",
        "    os.makedirs(dest_directory, exist_ok=True)\n",
        "    filename = DATA_URL.split('/')[-1]\n",
        "    filepath = os.path.join(dest_directory, filename)\n",
        "\n",
        "    if not os.path.exists(filepath):\n",
        "        def _progress(count, block_size, total_size):\n",
        "            sys.stdout.write('\\r>> Downloading {} {:.2%}%'.format(\n",
        "                filename, float(count * block_size) / float(total_size) * 100.0))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
        "        statinfo = os.stat(filepath)\n",
        "        print('\\nSuccessfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
        "\n",
        "    extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
        "    if not os.path.exists(extracted_dir_path):\n",
        "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S8ihRHHYt6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size =128\n",
        "data_dir='data/cifar/'\n",
        "model_dir=\"models/cifar\"\n",
        "NUM_CLASSES=10\n",
        "\n",
        "mode = tf.estimator.ModeKeys.TRAIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD01SJZMYu8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _variable_on_cpu(name, shape, initializer):\n",
        "  \"\"\"Helper to create a Variable stored on CPU memory.\n",
        "  Args:\n",
        "    name: name of the variable\n",
        "    shape: list of ints\n",
        "    initializer: initializer for Variable\n",
        "  Returns:\n",
        "    Variable Tensor\n",
        "  \"\"\"\n",
        "  with tf.device('/gpu:0'):\n",
        "    dtype = tf.float32\n",
        "    var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
        "  return var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvJGgNfZfuIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
        "  \"\"\"Helper to create an initialized Variable with weight decay.\n",
        "  Note that the Variable is initialized with a truncated normal distribution.\n",
        "  A weight decay is added only if one is specified.\n",
        "  Args:\n",
        "    name: name of the variable\n",
        "    shape: list of ints\n",
        "    stddev: standard deviation of a truncated Gaussian\n",
        "    wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
        "        decay is not added for this Variable.\n",
        "  Returns:\n",
        "    Variable Tensor\n",
        "  \"\"\"\n",
        "  dtype = tf.float32\n",
        "  var = _variable_on_cpu(\n",
        "      name,\n",
        "      shape,\n",
        "      tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
        "  if wd is not None:\n",
        "    weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
        "    tf.add_to_collection('losses', weight_decay)\n",
        "  return var\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcAd89cXHzBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def _activation_summary(x):\n",
        "  \"\"\"Helper to create summaries for activations.\n",
        "  Creates a summary that provides a histogram of activations.\n",
        "  Creates a summary that measures the sparsity of activations.\n",
        "  Args:\n",
        "    x: Tensor\n",
        "  Returns:\n",
        "    nothing\n",
        "  \"\"\"\n",
        "  # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
        "  # session. This helps the clarity of presentation on tensorboard.\n",
        "  tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
        "  tf.summary.histogram(tensor_name + '/activations', x)\n",
        "  tf.summary.scalar(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmd9SDdiYx5X",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6ZW7WzzYwvV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def l2_regularizer(wd):\n",
        "    def _l2_regularizer(var, name=None):\n",
        "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name=name)\n",
        "        tf.add_to_collection('losses', weight_decay)\n",
        "        return weight_decay\n",
        "    return _l2_regularizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPHmVx07Y5ew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_block(inputs, filters, kernel_size, name):\n",
        "    \"\"\"Builds a ConvBlock as seen in the section 2.3 slides.\n",
        "\n",
        "    Args:\n",
        "        inputs:\n",
        "        filters: {N}\n",
        "        kernel_size: {KS}\n",
        "        name:\n",
        "\n",
        "    Assumes we are using the default data format: NHWC\n",
        "\n",
        "    For the stuff below, let:\n",
        "        PS = pool_size\n",
        "        KS = kernel_size\n",
        "        S = stride for pooling\n",
        "\n",
        "    Output shapes can be computed with standard formulas, given stride=1:\n",
        "        Output height H <= (H - KS + 1 - PS)/S + 1\n",
        "        Output width: W <= (W - KS + 1 - PS)/S + 1\n",
        "    \"\"\"\n",
        "    with tf.variable_scope(name, 'conv_block'):\n",
        "        x = tf.layers.Conv2D(\n",
        "            filters, kernel_size,\n",
        "            padding='same',\n",
        "            use_bias=False)(inputs)\n",
        "\n",
        "            \n",
        "        x = tf.layers.BatchNormalization(\n",
        "            epsilon=1e-5,\n",
        "            fused=True,\n",
        "            name='batch_norm')(x, training=True)\n",
        "        x = tf.nn.relu(x, name='relu')\n",
        "        x = tf.layers.MaxPooling2D(\n",
        "            pool_size=3,\n",
        "            strides=2,\n",
        "            padding='same',\n",
        "            name='max_pool')(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6KKBAGSY91x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\n",
        "def inference(image_batch, batch_size=128):  # input batch of images and size\n",
        "    \"\"\"Build the CIFAR-10 model.\n",
        "    \n",
        "    Args:\n",
        "      image_batch: Images returned from distorted_inputs() or inputs().\n",
        "      batch_size: (int) number of examples per batch.\n",
        "    \n",
        "    Returns:\n",
        "      Logits.\n",
        "    \"\"\"\n",
        "\n",
        "    # ## Prep\n",
        "    # conv1\n",
        "\n",
        "    with tf.variable_scope('conv1') as scope:\n",
        "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 3,\n",
        "                64], stddev=5e-2, wd=None)\n",
        "        conv1 = tf.nn.conv2d(image_batch, kernel, [1, 1, 1, 1],\n",
        "                             padding='SAME')  # conv1\n",
        "        biases1 = _variable_on_cpu('biases1', [64],\n",
        "                                   tf.constant_initializer(0.0))\n",
        "        pre_activation1 = tf.nn.bias_add(conv1, biases1)\n",
        "        conv1 = tf.nn.relu(pre_activation1, name=scope.name)  # Relu 1\n",
        "        _activation_summary(conv1)\n",
        "\n",
        "        # norm1\n",
        "\n",
        "        norm1 = tf.nn.lrn(\n",
        "            conv1,\n",
        "            4,\n",
        "            bias=1.0,\n",
        "            alpha=0.001 / 9.0,\n",
        "            beta=0.75,\n",
        "            name='norm1',\n",
        "            )\n",
        "\n",
        "#####Layer 1\n",
        "\n",
        "# conv2\n",
        "\n",
        "    with tf.variable_scope('conv2') as scope:\n",
        "        kernel = _variable_with_weight_decay('weights', shape=[5, 5,\n",
        "                64, 64], stddev=5e-2, wd=None)\n",
        "        conv2 = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME'\n",
        "                             )  # Conv2\n",
        "        biases2 = _variable_on_cpu('biases2', [64],\n",
        "                                   tf.constant_initializer(0.1))\n",
        "        pre_activation2 = tf.nn.bias_add(conv2, biases2)\n",
        "        conv2 = tf.nn.relu(pre_activation2, name=scope.name)  # Relu 2\n",
        "        _activation_summary(conv2)\n",
        "\n",
        "        # norm2\n",
        "\n",
        "        norm2 = tf.nn.lrn(\n",
        "            conv2,\n",
        "            4,\n",
        "            bias=1.0,\n",
        "            alpha=0.001 / 9.0,\n",
        "            beta=0.75,\n",
        "            name='norm2',\n",
        "            )\n",
        "\n",
        "        # pool1\n",
        "\n",
        "        pool1 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1,\n",
        "                               2, 2, 1], padding='SAME', name='pool1')\n",
        "\n",
        "    # # res1 Layer 1\n",
        "\n",
        "    with tf.variable_scope('conv3') as scope:\n",
        "        kernel = _variable_with_weight_decay('weights', shape=[5, 5,\n",
        "                64, 64], stddev=5e-2, wd=None)\n",
        "        conv3 = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME'\n",
        "                             )  # Conv 3\n",
        "        biases3 = _variable_on_cpu('biases3', [64],\n",
        "                                   tf.constant_initializer(0.1))\n",
        "        pre_activation3 = tf.nn.bias_add(conv3, biases3)\n",
        "        conv3 = tf.nn.relu(pre_activation3, name=scope.name)  # Relu 3\n",
        "        _activation_summary(conv3)\n",
        "\n",
        "        # norm3\n",
        "\n",
        "        norm3 = tf.nn.lrn(\n",
        "            conv3,\n",
        "            4,\n",
        "            bias=1.0,\n",
        "            alpha=0.001 / 9.0,\n",
        "            beta=0.75,\n",
        "            name='norm3',\n",
        "            )\n",
        "\n",
        "    # ## Resnet 2 Layer 1\n",
        "\n",
        "    with tf.variable_scope('conv4') as scope:\n",
        "        kernel = _variable_with_weight_decay('weights', shape=[5, 5,\n",
        "                64, 64], stddev=5e-2, wd=None)\n",
        "        conv4 = tf.nn.conv2d(norm3, kernel, [1, 1, 1, 1], padding='SAME'\n",
        "                             )  # Conv2\n",
        "        biases4 = _variable_on_cpu('biases4', [64],\n",
        "                                   tf.constant_initializer(0.1))\n",
        "        pre_activation4 = tf.nn.bias_add(conv4, biases4)\n",
        "        conv4 = tf.nn.relu(pre_activation4, name=scope.name)  # Relu 2\n",
        "        _activation_summary(conv4)\n",
        "\n",
        "        # norm2\n",
        "\n",
        "        norm4 = tf.nn.lrn(\n",
        "            conv4,\n",
        "            4,\n",
        "            bias=1.0,\n",
        "            alpha=0.001 / 9.0,\n",
        "            beta=0.75,\n",
        "            name='norm2',\n",
        "            )\n",
        "\n",
        "        # # Do addition\n",
        "\n",
        "        # pool4\n",
        "\n",
        "        #pool4 = tf.nn.max_pool(norm4, ksize=[1, 3, 3, 1], strides=[1,\n",
        "         #                      2, 2, 1], padding='SAME', name='pool1')\n",
        "\n",
        "    # #################\n",
        "\n",
        "    with tf.variable_scope('flatten') as scope:\n",
        "    # Move everything into depth so we can perform a single matrix multiply.\n",
        "        reshape = tf.keras.layers.Flatten()(norm4)\n",
        "        dim = reshape.get_shape()[1].value\n",
        "        weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
        "                                              stddev=0.04, wd=0.004)\n",
        "        biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
        "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
        "        _activation_summary(local3)\n",
        "\n",
        "  # local4\n",
        "    with tf.variable_scope('local4') as scope:\n",
        "        weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
        "                                              stddev=0.04, wd=0.004)\n",
        "        biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
        "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
        "        _activation_summary(local4)\n",
        "\n",
        "  # linear layer(WX + b),\n",
        "  # We don't apply softmax here because\n",
        "  # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
        "  # and performs the softmax internally for efficiency.\n",
        "    with tf.variable_scope('softmax_linear') as scope:\n",
        "        weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
        "                                              stddev=1/192.0, wd=None)\n",
        "        biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
        "                                  tf.constant_initializer(0.0))\n",
        "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
        "        _activation_summary(softmax_linear)\n",
        "\n",
        "        return softmax_linear\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k83Z5pygZFD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def l2loss(logits, labels):\n",
        "    \"\"\"Add L2Loss to all the trainable variables.\n",
        "    Add summary for \"Loss\" and \"Loss/avg\".\n",
        "    Args:\n",
        "      logits: Logits from inference().\n",
        "      labels: Labels from distorted_inputs or inputs(). 1-D tensor\n",
        "              of shape [batch_size]\n",
        "    Returns:\n",
        "      Loss tensor of type float.\n",
        "    \"\"\"\n",
        "    # Calculate the average cross entropy loss across the batch.\n",
        "    labels = tf.cast(labels, tf.int64)\n",
        "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=labels, logits=logits, name='cross_entropy_per_example')\n",
        "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
        "    tf.add_to_collection('losses', cross_entropy_mean)\n",
        "    # The total loss is defined as the cross entropy loss plus all of the weight\n",
        "    # decay terms (L2 loss).\n",
        "    return tf.add_n(tf.get_collection('losses'), name='total_loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-zjs635DBLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _add_loss_summaries(total_loss):\n",
        "  \"\"\"Add summaries for losses in CIFAR-10 model.\n",
        "  Generates moving average for all losses and associated summaries for\n",
        "  visualizing the performance of the network.\n",
        "  Args:\n",
        "    total_loss: Total loss from loss().\n",
        "  Returns:\n",
        "    loss_averages_op: op for generating moving averages of losses.\n",
        "  \"\"\"\n",
        "  # Compute the moving average of all individual losses and the total loss.\n",
        "  loss_averages = tf.train.ExponentialMovingAverage(0.9, name='avg')\n",
        "  losses = tf.get_collection('losses')\n",
        "  loss_averages_op = loss_averages.apply(losses + [total_loss])\n",
        "\n",
        "  # Attach a scalar summary to all individual losses and the total loss; do the\n",
        "  # same for the averaged version of the losses.\n",
        "  for l in losses + [total_loss]:\n",
        "    # Name each loss as '(raw)' and name the moving average version of the loss\n",
        "    # as the original loss name.\n",
        "    tf.summary.scalar(l.op.name + ' (raw)', l)\n",
        "    tf.summary.scalar(l.op.name, loss_averages.average(l))\n",
        "\n",
        "  return loss_averages_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RNNZM20ZH5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(logits,labels):\n",
        "\n",
        "    acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(labels, 1), \n",
        "                                  predictions=tf.argmax(logits,1))\n",
        "    \n",
        "    tf.add_to_collection('accuracy', acc)\n",
        "    \n",
        "    return acc, acc_op\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctu4_eS5DH5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(total_loss, batch_size):\n",
        "  \"\"\"Train CIFAR-10 model.\n",
        "  Create an optimizer and apply to all trainable variables. Add moving\n",
        "  average for all trainable variables.\n",
        "  Args:\n",
        "    total_loss: Total loss from loss().\n",
        "    global_step: Integer Variable counting the number of training steps\n",
        "      processed.\n",
        "  Returns:\n",
        "    train_op: op for training.\n",
        "  \"\"\"\n",
        "  # Variables that affect learning rate.\n",
        "\n",
        "  global_step=tf.train.get_or_create_global_step()\n",
        "  num_batches_per_epoch = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN / FLAGS.batch_size\n",
        "  decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
        "\n",
        "  # Decay the learning rate exponentially based on the number of steps.\n",
        "  lr = tf.train.exponential_decay(INITIAL_LEARNING_RATE,\n",
        "                                  global_step,\n",
        "                                  decay_steps,\n",
        "                                  LEARNING_RATE_DECAY_FACTOR,\n",
        "                                  staircase=True)\n",
        "  tf.summary.scalar('learning_rate', lr)\n",
        "\n",
        "  # Generate moving averages of all losses and associated summaries.\n",
        "  loss_averages_op = _add_loss_summaries(total_loss)\n",
        "\n",
        "  update_ops=tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "\n",
        "  # Compute gradients.\n",
        "  with tf.control_dependencies([loss_averages_op]):\n",
        "    opt = tf.train.GradientDescentOptimizer(lr)\n",
        "    \n",
        "    grads = opt.compute_gradients(total_loss)\n",
        "\n",
        "  # Apply gradients.\n",
        "  apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n",
        "\n",
        "  # Add histograms for trainable variables.\n",
        "  for var in tf.trainable_variables():\n",
        "    tf.summary.histogram(var.op.name, var)\n",
        "\n",
        "  # Add histograms for gradients.\n",
        "  for grad, var in grads:\n",
        "    if grad is not None:\n",
        "      tf.summary.histogram(var.op.name + '/gradients', grad)\n",
        "\n",
        "  # Track the moving averages of all trainable variables.\n",
        "  variable_averages = tf.train.ExponentialMovingAverage(\n",
        "      MOVING_AVERAGE_DECAY, global_step)\n",
        "  with tf.control_dependencies([apply_gradient_op]):\n",
        "    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
        "\n",
        "  return variables_averages_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1VmpB0JZL_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(total_loss, batch_size):\n",
        "    global_step = tf.train.get_or_create_global_step()\n",
        "    num_examples_per_epoch_for_train = 50000 # Number of training samples\n",
        "    num_epochs_per_decay = 350.0\n",
        "    num_batches_per_epoch = num_examples_per_epoch_for_train / batch_size  # Calculate number of batches for each epoch\n",
        "    decay_steps = int(num_batches_per_epoch * num_epochs_per_decay)\n",
        "    lr = tf.train.exponential_decay(\n",
        "        0.1, global_step, decay_steps,\n",
        "        decay_rate=0.1, staircase=True)\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS) # To ensure anything in below code block is run already\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        train_op = tf.contrib.layers.optimize_loss(\n",
        "            loss=total_loss,\n",
        "            global_step=global_step,\n",
        "            learning_rate=lr,\n",
        "            optimizer='SGD')         \n",
        "    return train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92tp2YJpNGyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO8yVu6wZPi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CIFAR-10 consists of 50K training examples and 10K eval examples.\n",
        "# Each image has size 32x32 (and depth 3 for RGB).\n",
        "CIFAR_TRAIN_SIZE = 50000\n",
        "CIFAR_EVAL_SIZE = 10000\n",
        "CIFAR_IMAGE_SIZE = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_rGdkabqrc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def augment(images, labels,\n",
        "            resize=None, # (width, height) tuple or None\n",
        "            horizontal_flip=False,\n",
        "            vertical_flip=False,\n",
        "            rotate=0, # Maximum rotation angle in degrees\n",
        "            crop_probability=0, # How often we do crops\n",
        "            crop_min_percent=0.6, # Minimum linear dimension of a crop\n",
        "            crop_max_percent=1.,  # Maximum linear dimension of a crop\n",
        "            mixup=0):  # Mixup coeffecient, see https://arxiv.org/abs/1710.09412.pdf\n",
        "  if resize is not None:\n",
        "    images = tf.image.resize_bilinear(images, resize)\n",
        "  print(\"1 --->\",images)\n",
        "  # My experiments showed that casting on GPU improves training performance\n",
        "  if images.dtype != tf.float32:\n",
        "    images = tf.image.convert_image_dtype(images, dtype=tf.float32)\n",
        "    print(\"2 --->\",images)\n",
        "    images = tf.subtract(images, 0.5)\n",
        "    print(\"3 --->\",images)\n",
        "    images = tf.multiply(images, 2.0)\n",
        "    print(\"4 --->\",images)\n",
        "  labels = tf.to_float(labels)\n",
        "  print(\"labels --->\",labels)\n",
        "  \n",
        "  with tf.name_scope('augmentation'):\n",
        "    shp = tf.shape(images)\n",
        "    print(\"shp --->\",shp)\n",
        "    batch_size, height, width = shp[0], shp[1], shp[2]\n",
        "    print(\"batch_size --->\",batch_size)\n",
        "    width = tf.cast(width, tf.float32)\n",
        "    print(\"width --->\",width)\n",
        "    height = tf.cast(height, tf.float32)\n",
        "    print(\"height --->\",height)\n",
        "      \n",
        "    print(batch_size,width,height)\n",
        "    # The list of affine transformations that our image will go under.\n",
        "    # Every element is Nx8 tensor, where N is a batch size.\n",
        "    transforms = []\n",
        "    identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n",
        "    if horizontal_flip:\n",
        "      print(\"IN horizontal_flip\")\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [-1., 0., width, 0., 1., 0., 0., 0.], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if vertical_flip:\n",
        "      print(\"IN vertical_flip\")\n",
        "      coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), 0.5)\n",
        "      flip_transform = tf.convert_to_tensor(\n",
        "          [1, 0, 0, 0, -1, height, 0, 0], dtype=tf.float32)\n",
        "      transforms.append(\n",
        "          tf.where(coin,\n",
        "                   tf.tile(tf.expand_dims(flip_transform, 0), [batch_size, 1]),\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if rotate > 0:\n",
        "      print(\"rotate\")\n",
        "      angle_rad = rotate / 180 * math.pi\n",
        "      angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n",
        "      transforms.append(\n",
        "          tf.contrib.image.angles_to_projective_transforms(\n",
        "              angles, height, width))\n",
        "\n",
        "    if crop_probability > 0:\n",
        "      print(\"crop_probability\")\n",
        "      crop_pct = tf.random_uniform([batch_size], crop_min_percent,\n",
        "                                   crop_max_percent)\n",
        "      left = tf.random_uniform([batch_size], 0, width * (1 - crop_pct))\n",
        "      top = tf.random_uniform([batch_size], 0, height * (1 - crop_pct))\n",
        "      crop_transform = tf.stack([\n",
        "          crop_pct,\n",
        "          tf.zeros([batch_size]), top,\n",
        "          tf.zeros([batch_size]), crop_pct, left,\n",
        "          tf.zeros([batch_size]),\n",
        "          tf.zeros([batch_size])\n",
        "      ], 1)\n",
        "\n",
        "      coin = tf.less(\n",
        "          tf.random_uniform([batch_size], 0, 1.0), crop_probability)\n",
        "      transforms.append(\n",
        "          tf.where(coin, crop_transform,\n",
        "                   tf.tile(tf.expand_dims(identity, 0), [batch_size, 1])))\n",
        "\n",
        "    if transforms:\n",
        "      print(\"transforms\")\n",
        "      images = tf.contrib.image.transform(\n",
        "          images,\n",
        "          tf.contrib.image.compose_transforms(*transforms),\n",
        "          interpolation='BILINEAR') # or 'NEAREST'\n",
        "\n",
        "    def cshift(values): # Circular shift in batch dimension\n",
        "      return tf.concat([values[-1:, ...], values[:-1, ...]], 0)\n",
        "\n",
        "    if mixup > 0:\n",
        "      print(\"is mixup reqd\")\n",
        "      mixup = 1.0 * mixup # Convert to float, as tf.distributions.Beta requires floats.\n",
        "      print(\"mixup is \",mixup)\n",
        "      beta = tf.distributions.Beta(mixup, mixup)\n",
        "      print(\"beta is \",beta)\n",
        "      lam = beta.sample(batch_size)\n",
        "      print(\"lam is \",lam)\n",
        "      ll = tf.expand_dims(tf.expand_dims(tf.expand_dims(lam, -1), -1), -1)\n",
        "      print(\"ll is \",ll)\n",
        "      images = ll * images + (1 - ll) * cshift(images)\n",
        "      print(\"images is \",images)\n",
        "      labels = lam * labels + (1 - lam) * cshift(labels)\n",
        "      print(\"labels is \",labels)\n",
        "\n",
        "  return images, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0kbS-eHawHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "def input_fn(data_dir,batch_size): # input parameter dir of cifar 10 data and batch size\n",
        "    # The src of data will be downloaded to pwd when running first time\n",
        "    filenames = glob(os.path.join(data_dir, 'cifar-10-batches-bin', 'data_batch_*.bin')) # List all filenames inside cifar-10-batches-bin directory and list all filenames matching data_batch_*.bin \n",
        "    pprint(filenames)\n",
        "\n",
        "    depth = 3\n",
        "    height = width = CIFAR_IMAGE_SIZE\n",
        "    label_bytes = 1\n",
        "    image_bytes = height * width * depth\n",
        "    # Every record consists of a label followed by the image,\n",
        "    # with a fixed number of bytes for each.\n",
        "    record_bytes = label_bytes + image_bytes\n",
        "\n",
        "    def decode_line(value): # Convert binary record into image tensor and it's corresponding label\n",
        "        \"\"\"Additional processing to perform on each line in dataset.\"\"\"\n",
        "        record_bytes = tf.decode_raw(value, tf.uint8) # 1. Convert each byte into integer representation\n",
        "        # The first bytes represent the label, which we convert from uint8->int32.\n",
        "        label = tf.to_int32(tf.strided_slice(record_bytes, [0], [label_bytes]))\n",
        "        # The remaining bytes after the label represent the image, which we reshape\n",
        "        # from [depth * height * width] to [depth, height, width].\n",
        "        depth_major = tf.reshape(\n",
        "            tf.strided_slice(record_bytes, [label_bytes], [label_bytes + image_bytes]),\n",
        "            [depth, height, width])\n",
        "        # Convert from [depth, height, width] to [height, width, depth].\n",
        "        uint8image = tf.transpose(depth_major, [1, 2, 0])\n",
        "        reshaped_image = tf.cast(uint8image, tf.float32)\n",
        "        # Randomly flip the image horizontally.\n",
        "        distorted_image = augment(reshaped_image, label,\n",
        "                         horizontal_flip=True, rotate=15, crop_probability=0.8, mixup=4)\n",
        "        #distorted_image = tf.image.random_flip_left_right(reshaped_image)\n",
        "        # Subtract off the mean and divide by the variance of the pixels.\n",
        "        float_image = tf.image.per_image_standardization(distorted_image)\n",
        "        # Set the shapes of tensors.\n",
        "        float_image.set_shape([height, width, 3])\n",
        "        label.set_shape([1])\n",
        "        return float_image, label\n",
        "\n",
        "    # Repeat infinitely.\n",
        "    dataset = tf.data.FixedLengthRecordDataset(filenames, record_bytes).repeat() # expects list of filenames and number of bytes each record takes \n",
        "    dataset = dataset.map(decode_line, num_parallel_calls=batch_size) # Converts binary record into image tensor\n",
        "\n",
        "    min_fraction_of_examples_in_queue = 0.4\n",
        "    min_queue_examples = int(CIFAR_TRAIN_SIZE * min_fraction_of_examples_in_queue)\n",
        "    dataset = dataset.shuffle(buffer_size=min_queue_examples + 3 * batch_size) # Customise data shuffle in input pipeline\n",
        "\n",
        "    # Batch it up.\n",
        "    dataset = dataset.batch(batch_size) # Set batch size\n",
        "    iterator = dataset.make_one_shot_iterator() # Iterate over batches returning image batch, label pairs\n",
        "    image_batch, label_batch = iterator.get_next() # Retrieves sequence of batches\n",
        "    # Ensure we don't have any shape dimensions equal to None...\n",
        "    image_batch.set_shape([batch_size, height, width, 3])\n",
        "    label_batch = tf.squeeze(label_batch)\n",
        "    return image_batch, label_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZAfjSEJazWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def model_fn(features, labels, mode):\n",
        "     logits = inference(\n",
        "        image_batch=features,\n",
        "        batch_size=batch_size)\n",
        "    \n",
        "     loss =l2loss(logits, labels)\n",
        "     \n",
        "     train_op =train(loss, batch_size=batch_size)\n",
        "\n",
        "     if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        logging_hook = tf.train.LoggingTensorHook({'loss': loss}, every_n_iter=1)\n",
        "        return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            loss=loss,\n",
        "            train_op=train_op,\n",
        "            \n",
        "            training_hooks=[logging_hook])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K81yyBiAa8eT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    # Ensure data_dir has dataset and model_dir is cleared before training.\n",
        "    maybe_download_and_extract(data_dir=data_dir) # Download data if not exist in data dir specified\n",
        "    if tf.gfile.Exists(model_dir):\n",
        "        tf.gfile.DeleteRecursively(model_dir)\n",
        "    tf.gfile.MakeDirs(model_dir)  # Clear model dir before instatiating\n",
        "\n",
        "    \n",
        "    classifier = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        model_dir=model_dir)\n",
        "    classifier.train(\n",
        "        input_fn=lambda: input_fn(data_dir, batch_size),\n",
        "        steps=20) # Train classifier calls model_fn build entire model graph  look past input function and do training updates used simple callable a funtion can be called without param by wrapping in lambda\n",
        "   \n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtA7_0Ta_U1",
        "colab_type": "code",
        "outputId": "e0d6c52f-a8d7-4355-8dcf-928986beb282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0817 04:02:40.926733 139804540036992 estimator.py:1790] Using default config.\n",
            "I0817 04:02:40.929874 139804540036992 estimator.py:209] Using config: {'_model_dir': 'models/cifar', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2612e668d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['data/cifar/cifar-10-batches-bin/data_batch_5.bin',\n",
            " 'data/cifar/cifar-10-batches-bin/data_batch_1.bin',\n",
            " 'data/cifar/cifar-10-batches-bin/data_batch_2.bin',\n",
            " 'data/cifar/cifar-10-batches-bin/data_batch_4.bin',\n",
            " 'data/cifar/cifar-10-batches-bin/data_batch_3.bin']\n",
            "1 ---> Tensor(\"Cast:0\", shape=(32, 32, 3), dtype=float32)\n",
            "labels ---> Tensor(\"ToFloat:0\", shape=(?,), dtype=float32)\n",
            "shp ---> Tensor(\"augmentation/Shape:0\", shape=(3,), dtype=int32)\n",
            "batch_size ---> Tensor(\"augmentation/strided_slice:0\", shape=(), dtype=int32)\n",
            "width ---> Tensor(\"augmentation/Cast:0\", shape=(), dtype=float32)\n",
            "height ---> Tensor(\"augmentation/Cast_1:0\", shape=(), dtype=float32)\n",
            "Tensor(\"augmentation/strided_slice:0\", shape=(), dtype=int32) Tensor(\"augmentation/Cast:0\", shape=(), dtype=float32) Tensor(\"augmentation/Cast_1:0\", shape=(), dtype=float32)\n",
            "IN horizontal_flip\n",
            "rotate\n",
            "crop_probability\n",
            "transforms\n",
            "is mixup reqd\n",
            "mixup is  4.0\n",
            "beta is  tfp.distributions.Beta(\"augmentation/Beta/\", batch_shape=(), event_shape=(), dtype=float32)\n",
            "lam is  Tensor(\"augmentation/Beta/sample/Reshape_1:0\", shape=(32,), dtype=float32)\n",
            "ll is  Tensor(\"augmentation/ExpandDims_5:0\", shape=(32, 1, 1, 1), dtype=float32)\n",
            "images is  Tensor(\"augmentation/add:0\", shape=(32, 32, 32, 3), dtype=float32)\n",
            "labels is  Tensor(\"augmentation/add_1:0\", shape=(32,), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Shapes must be equal rank, but are 4 and 1\n\tFrom merging shape 0 with other shapes. for 'per_image_standardization/image' (op: 'Pack') with input shapes: [32,32,32,3], [32].",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-174f78df48e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-4f64f23f57b1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     classifier.train(\n\u001b[1;32m     13\u001b[0m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         steps=20) # Train classifier calls model_fn build entire model graph  look past input function and do training updates used simple callable a funtion can be called without param by wrapping in lambda\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1183\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m   1184\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[0;32m-> 1185\u001b[0;31m               input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[1;32m   1186\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m       estimator_spec = self._call_model_fn(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[0;34m(self, input_fn, mode)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[0;32m-> 1022\u001b[0;31m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[0;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[1;32m   1111\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_context'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-4f64f23f57b1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         model_dir=model_dir)\n\u001b[1;32m     12\u001b[0m     classifier.train(\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         steps=20) # Train classifier calls model_fn build entire model graph  look past input function and do training updates used simple callable a funtion can be called without param by wrapping in lambda\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-dc85f37c02a1>\u001b[0m in \u001b[0;36minput_fn\u001b[0;34m(data_dir, batch_size)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# Repeat infinitely.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFixedLengthRecordDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# expects list of filenames and number of bytes each record takes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Converts binary record into image tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmin_fraction_of_examples_in_queue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1774\u001b[0m       return DatasetV1Adapter(\n\u001b[1;32m   1775\u001b[0m           ParallelMapDataset(\n\u001b[0;32m-> 1776\u001b[0;31m               self, map_func, num_parallel_calls, preserve_cardinality=False))\n\u001b[0m\u001b[1;32m   1777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Use `tf.data.Dataset.map()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3226\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3227\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3229\u001b[0m     self._num_parallel_calls = ops.convert_to_tensor(\n\u001b[1;32m   3230\u001b[0m         num_parallel_calls, dtype=dtypes.int32, name=\"num_parallel_calls\")\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   2553\u001b[0m       \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2557\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 1355\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1650\u001b[0m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   1546\u001b[0m         self._function_attributes)\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    713\u001b[0m                                           converted_func)\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2547\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   2548\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_to_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-dc85f37c02a1>\u001b[0m in \u001b[0;36mdecode_line\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#distorted_image = tf.image.random_flip_left_right(reshaped_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Subtract off the mean and divide by the variance of the pixels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mfloat_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mper_image_standardization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistorted_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Set the shapes of tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mfloat_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mper_image_standardization\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m   1492\u001b[0m   \"\"\"\n\u001b[1;32m   1493\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'per_image_standardization'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_AssertAtLeast3DImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m     \u001b[0mnum_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[1;32m   1085\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[1;32m   1086\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[0;32m-> 1087\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\u001b[0m\n\u001b[1;32m   1222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cast_nested_seqs_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_autopacking_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"packed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_autopacking_helper\u001b[0;34m(list_or_tuple, dtype, name)\u001b[0m\n\u001b[1;32m   1093\u001b[0m           elems_as_tensors.append(\n\u001b[1;32m   1094\u001b[0m               constant_op.constant(elem, dtype=dtype, name=str(i)))\n\u001b[0;32m-> 1095\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melems_as_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_elems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5896\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 5897\u001b[0;31m         \"Pack\", values=values, axis=axis, name=name)\n\u001b[0m\u001b[1;32m   5898\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5899\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    462\u001b[0m     return super(FuncGraph, self).create_op(\n\u001b[1;32m    463\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         compute_device=compute_device)\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 4 and 1\n\tFrom merging shape 0 with other shapes. for 'per_image_standardization/image' (op: 'Pack') with input shapes: [32,32,32,3], [32]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn4NNsHLGOIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S088QtP-edd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}